NAME: Kevin Zhang
EMAIL: kevin.zhang.13499@gmail.com
ID: 104939334
SLIPDAYS: 0

Files:
lab2_list.c: Source file that performs the operation of inserting and deleting from a Sorted linked list via p_threading using splitting one linked list into multiple separate ones to help with synchronization and reduce the number of context switches 
SortedList.h: header file with implementation of SortedList
SortedList.c: source code for SortedList containing insert, delete, lookup, and length
Makefile: make file with build, dist, clean, tests, profile and graphs
lab2_list.csv: CSV files with all of the generated data from lab2_list.c
lab2b_1.png: Throughput vs # of Threads
lab2b_2.png: Mean Time for Wait and Mean Time per Operation
lab2b_3.png: Successful Iterations
lab2b_4.png: Throughput vs # of Threads for Mutex
lab2b_5.png: Throughput vs # of Threads for Spin Lock
profile.out: execution profile generated by Google's pprof tool to examine the test case with 1000 iterations, 12 threads, and spin-lock protection

README: file explaining this tarball


References:
http://man7.org/linux/man-pages/man7/pthreads.7.html
https://www.cs.cmu.edu/~adamchik/15-121/lectures/Linked%20Lists/linked%20lists.html
 http://www.cse.yorku.ca/~oz/hash.html
Questions
QUESTION 2.3.1 - CPU time in the basic list implementation:
Where do you believe most of the CPU time is spent in the 1 and 2-thread list tests ?
Most of the CPU's time should be spent actually executing the relevant list operations code because the number
of threads is few and as a result, the number of context switches is reduced. Almost all of the time for 1-thread 
executions will be spent executing list operations. However, for 2-threads, a small proportion of this time will be 
spent actually performing lock operations, especially in the case of spin locking. 

Why do you believe these to be the most expensive parts of the code?
List operations are the most expensive because they inherently require more operations and instructions than regular
arithmetic instructions or output. List operations involve pointer-manipulation and reassignment and deals with a 
non-primitive complex data structure, a circular sorted linked list. Locking isn't as expensive because there is very
little locking involved in the execution of 1-2 thread tests. The overhead of context switching is overshadowed by the
bulk of the list management.

Where do you believe most of the CPU time is being spent in the high-thread spin-lock tests?
For tests involving the spin lock, most of the CPU time is devoted to spinning cycles as threads wait for the CPU. As 
the number of threads increase, the number of context switches also increases. Furthermore, when there is a possibility
of multiple threads spinning for a single section furthr increasing the wait times. Therefore, most of the CPU time is 
spent, spinning for a required lock.

Where do you believe most of the CPU time is being spent in the high-thread mutex tests?
Although there are more threads, most of the CPU time is still spent performing linked list operations. This is because
although the number of context switches increase, the threads are merely put to sleep and woken up so no wasted CPU
cycles occur. The number of instructions and the percentage of time spent is still higher for linked list operations 
and context switches happen if and only if a collision occurs. 

2.3.3
Look at the average time per operation (vs. # threads) and the average wait-for-mutex time (vs. #threads).
Why does the average lock-wait time rise so dramatically with the number of contending threads?

The number of contending threads increases the average lock-wait time dramatically because the number of contentions increase.
Many more threads wait for a lock, so each thread has to wait more time to acquire the lock. The more threads there are, the more
threads will be waiting for each lock so the average wait time increases also.

Why does the completion time per operation rise (less dramatically) with the number of contending threads?

Completion time per operation doesn't have as dramatic of a rise because completion time depends partially on locking. As the number of
threads increase, so does the time spent in the locking mode. However, the time spent completing other tasks is not affected by the number of threads running
so the overall factor of increase is offset by the bulk of time actually executing relevant code. 

How is it possible for the wait time per operation to go up faster (or higher) than the completion time per operation?

As mentioned previously, wait time is directly dependent on the number of threads. The higher the number of threads, the more threads will be contending for a particular resource at a given moment 
which means the time will definitely increase. Completion time on the other hand, is partly increased by the waiting time increase from context switching and waiting. However,
only a portion of the completion time is actually increasing while the other part is unaffected. Therefore, the increase is only proportional to a percentage of 
the completion time and therefore is less dramatic.

QUESTION 2.3.4 - Performance of Partitioned Lists
Explain the change in performance of the synchronized methods as a function of the number of lists.
The greater the number of lists, the easier synchronization is for a larger number of threads. Threads can split up the work more easily because the lists
as split up. A group or preferably, 1 thread, can work on each sub-list at a time, reducing the number of threads working on each separate list. As the lists length 
decreases, the number of threads working on each sublist at a time decreases. Since the lists are worked on by less threads, there will be fewer collisions between
 threads working on different sublists. Only when there are more threads than lists will there be collisions. However,since the number of threads 
per critical section is fewer, the performance is still higher than with only 1 list.

Should the throughput continue increasing as the number of lists is further increased? If not, explain why not.
As the number of lists increase, there will be a point where there is no longer any contention of data. This happens when each sublist is worked on by 1 thread only. 
After that point, adding more lists will not help at all and will actually decrease throughput because there is increased number of lock operations without any 
increase in performance.
It seems reasonable to suggest the throughput of an N-way partitioned list should be equivalent to the throughput of a single list with fewer (1/N) threads. Does this appear to be true in the above curves? If not, explain why not.
It doesn't seem reasonable because partitioning decreases the chance of contentions. However the same number of threads in one giant list will still have more threads, 
on average N times as many threads working in the same critical section as any particular 1/N sublist which clearly sees many more collisions of simultaneously accesses
to the critical section. Therefore, they are no equivalent.
